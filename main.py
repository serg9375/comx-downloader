import os
import sys
import time
import json
import re
import cloudscraper
import requests.cookies
import zipfile
import rarfile
import inquirer
import img2pdf
import shutil
import tempfile
from pathlib import Path
from PIL import Image
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options as ChromeOptions
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.firefox.service import Service as FirefoxService
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from webdriver_manager.firefox import GeckoDriverManager
from urllib.parse import urljoin, urlparse, quote

# --- –¶–≤–µ—Ç–∞ –∏ –°—Ç–∏–ª–∏ ---
CYAN = '\033[96m'
YELLOW = '\033[93m'
GREY = '\033[90m'
MAGENTA_BG = '\033[45m'
BLACK_FG = '\033[30m'
BOLD = '\033[1m'
RED = '\033[91m'
GREEN = '\033[92m'
ENDC = '\033[0m'
SEPARATOR = f"\n{GREY}‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ{ENDC}"

def clear_console():
    # Use ANSI escape codes for better compatibility with inquirer
    # \033[2J - Clear entire screen
    # \033[H - Move cursor to home position (top-left)
    if os.name == 'nt':
        os.system('cls')
    else:
        print('\033[2J\033[H', end='', flush=True)

def print_menu():
    title = f"{MAGENTA_BG}{BLACK_FG}{BOLD} COM-X.LIFE Downloader{ENDC}"
    author = f"{BOLD}–ê–≤—Ç–æ—Ä: https://github.com/smutchev{ENDC}"
    print(f"\n{title}  {author}\n")

class ComXLifeDownloader:
    def __init__(self, browser_choice='chrome', debug=False):
        self.debug = debug
        self.base_url = "https://com-x.life"
        self.session = cloudscraper.create_scraper(
            browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False},
            delay=1
        )
        self.cookies = {}
        self.browser_choice = browser_choice
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Referer': self.base_url
        }

    def get_cookies_via_selenium(self):
        print(SEPARATOR)
        print("–ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø")
        driver = None
        browser_name_display = self.browser_choice.capitalize()
        try:
            if self.browser_choice == 'chrome':
                chrome_options = ChromeOptions()
                chrome_options.add_argument("--disable-blink-features=AutomationControlled")
                chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
                chrome_options.add_experimental_option('useAutomationExtension', False)
                service = ChromeService(ChromeDriverManager().install())
                driver = webdriver.Chrome(service=service, options=chrome_options)
            elif self.browser_choice == 'firefox':
                ff_options = FirefoxOptions()
                ff_options.set_preference("dom.webdriver.enabled", False)
                ff_options.set_preference('useAutomationExtension', False)
                ff_options.set_preference("general.useragent.override", self.headers['User-Agent'])
                service = FirefoxService(GeckoDriverManager().install())
                driver = webdriver.Firefox(service=service, options=ff_options)
            else:
                 print(f"‚úó –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –±—Ä–∞—É–∑–µ—Ä: {self.browser_choice}")
                 return False
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ {browser_name_display}: {e}")
            print(f"\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å {browser_name_display} –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ { 'ChromeDriver' if self.browser_choice == 'chrome' else 'GeckoDriver' }")
            return False
        if not driver:
             print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥—Ä–∞–π–≤–µ—Ä")
             return False
        try:
            driver.get(self.base_url)
            print(f"\n‚ö† –°–µ–π—á–∞—Å {browser_name_display} –æ—Ç–∫—Ä—ã—Ç")
            print("üìù –í–æ–π–¥–∏—Ç–µ –≤ —Å–≤–æ–π –∞–∫–∫–∞—É–Ω—Ç –Ω–∞ —Å–∞–π—Ç–µ com-x.life")
            print("‚è≥ –°–∫—Ä–∏–ø—Ç *–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏* –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É –ø–æ—Å–ª–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—Ö–æ–¥–∞...")
            while True:
                try:
                    _ = driver.current_url
                    if driver.get_cookie("dle_user_id"):
                        print("\n‚úì –û–±–Ω–∞—Ä—É–∂–µ–Ω –≤—Ö–æ–¥! –ü–æ–ª—É—á–∞–µ–º cookies...")
                        cookies_list = driver.get_cookies()
                        for cookie in cookies_list:
                            self.cookies[cookie['name']] = cookie['value']
                        # Create a new cookie jar to completely replace session cookies (avoids duplicates)
                        new_jar = requests.cookies.RequestsCookieJar()
                        for name, value in self.cookies.items():
                            new_jar.set(name, value, domain='com-x.life')
                        self.session.cookies = new_jar
                        if self.cookies:
                            self.save_cookies()
                            print(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(self.cookies)} cookies\n")
                            return True
                        else:
                            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å cookies, —Ö–æ—Ç—è –≤—Ö–æ–¥ –±—ã–ª –æ–±–Ω–∞—Ä—É–∂–µ–Ω.")
                            return False
                    time.sleep(1)
                except Exception:
                    print("\n‚úó –ë—Ä–∞—É–∑–µ—Ä –±—ã–ª –∑–∞–∫—Ä—ã—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.")
                    return False
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return False
        finally:
            try:
                driver.quit()
            except Exception:
                pass
        return False

    def save_cookies(self):
        cookies_file = Path('comx_cookies.json')
        with open(cookies_file, 'w', encoding='utf-8') as f:
            json.dump(self.cookies, f)
        print(f"‚úì Cookies —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {cookies_file}")

    def load_cookies(self):
        cookies_file = Path('comx_cookies.json')
        if cookies_file.exists():
            try:
                with open(cookies_file, 'r', encoding='utf-8') as f:
                    self.cookies = json.load(f)
                    # Create a new cookie jar to completely replace session cookies (avoids duplicates)
                    new_jar = requests.cookies.RequestsCookieJar()
                    for name, value in self.cookies.items():
                        new_jar.set(name, value, domain='com-x.life')
                    self.session.cookies = new_jar
                print("‚úì Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞")
                return True
            except Exception:
                pass
        return False

    def get_manga_id_from_url(self, url):
        match = re.search(r'/(\d+)-', url)
        if match:
            return match.group(1)
        return None

    def _perform_search_page(self, query, page=1):
        try:
            encoded_query = quote(query)
            search_url = f"{self.base_url}/search/{encoded_query}/page/{page}/" if page > 1 else f"{self.base_url}/search/{encoded_query}"
            response = self.session.get(search_url, headers=self.headers)
            if response.status_code != 200:
                return []
            soup = BeautifulSoup(response.content, 'lxml')
            content = soup.find('div', id='dle-content')
            if not content:
                return []
            results = []
            title_tags = content.find_all('h3', class_='readed__title')
            if not title_tags:
                return []
            for title_tag in title_tags:
                if title_tag.a:
                    title = title_tag.a.text.strip()
                    url = title_tag.a['href']
                    if not url.startswith('http'):
                        url = urljoin(self.base_url, url)
                    results.append({'title': title, 'url': url})
            return results
        except Exception:
            return []

    def fetch_search_results_sync(self, query):
        all_results = []
        current_page = 1
        limit = 30
        while len(all_results) < limit:
            page_results = self._perform_search_page(query, page=current_page)
            if not page_results:
                break
            all_results.extend(page_results)
            current_page += 1
        return all_results[:limit]

    def get_chapters_list(self, manga_url):
        print(SEPARATOR)
        print("–ü–û–õ–£–ß–ï–ù–ò–ï –°–ü–ò–°–ö–ê –ì–õ–ê–í")
        clean_url = manga_url.split('#')[0]
        response = self.session.get(clean_url, headers=self.headers)
        if response.status_code != 200:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {response.status_code}")
            if "Just a moment..." in response.text or response.status_code == 403:
                 print("‚úó –ü–æ—Ö–æ–∂–µ –Ω–∞ –∑–∞—â–∏—Ç—É Cloudflare –∏–ª–∏ –±–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–¥–∞–ª–∏—Ç—å comx_cookies.json –∏ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –∑–∞–Ω–æ–≤–æ.")
            return None, None
        soup = BeautifulSoup(response.content, 'lxml')
        script_data = None
        for script in soup.find_all('script'):
            if script.string and 'window.__DATA__' in script.string:
                script_data = script.string
                break
        if not script_data:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –æ –≥–ª–∞–≤–∞—Ö (window.__DATA__)")
            return None, None
        try:
            json_match = re.search(r'window\.__DATA__\s*=\s*({.+?});', script_data, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(1))
                chapters = data.get('chapters', [])
                chapters.sort(key=lambda x: x.get('posi', 0))
                manga_title_raw = data.get("title", "Unknown Manga")
                manga_title = self.sanitize_filename(manga_title_raw)
                print(f"‚úì –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤: {len(chapters)}")
                print(f"‚úì –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–Ω–≥–∏: {manga_title}\n")
                return chapters, manga_title
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None, None

    def download_chapter(self, chapter, base_manga_folder, news_id, manga_url):
        start_time = time.time()
        chapter_id = chapter['id']
        chapter_title_raw = chapter.get('title', f"–ì–ª–∞–≤–∞ {chapter.get('number', '?')}")
        chapter_posi = chapter.get('posi', 0)

        match = re.match(r'^\s*([\d\.]+)\s*-\s*([\d\.]+)\s*(.*)', chapter_title_raw)
        if match:
            vol = match.group(1).strip()
            ch = match.group(2).strip()
            title = match.group(3).strip()
            chapter_name = f"Vol. {vol} Ch. {ch} - {title}"
        else:
            chapter_name = f"Ch. {chapter_posi:03d} - {chapter_title_raw}"

        chapter_title_safe = self.sanitize_filename(chapter_name)
        chapter_folder = base_manga_folder / chapter_title_safe

        if chapter_folder.exists() and any(f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.webp'] for f in chapter_folder.iterdir()):
            print(f"  ‚äò {chapter_title_safe} (–ø—Ä–æ–ø—É—â–µ–Ω–æ)")
            return True

        chapter_folder.mkdir(parents=True, exist_ok=True)
        temp_archive_path = None

        # ========================================================================
        # === –ò–ó–ú–ï–ù–ï–ù–ò–ï (v5.9): –£–±—Ä–∞–Ω Spinner ===
        # ========================================================================
        if self.debug:
            print(f"  üîó –°–∫–∞—á–∏–≤–∞—é: {chapter_title_safe}...")
        else:
            print(f"  üîó –°–∫–∞—á–∏–≤–∞—é: {chapter_title_safe}...", end="", flush=True)

        try:
            api_url = f"{self.base_url}/engine/ajax/controller.php?mod=api&action=chapters/download"
            payload = f"chapter_id={chapter_id}&news_id={news_id}"
            api_headers = self.headers.copy()
            api_headers.update({
                "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
                "Referer": manga_url,
                "X-Requested-With": "XMLHttpRequest",
                "Origin": self.base_url
            })

            link_resp = self.session.post(api_url, headers=api_headers, data=payload)

            if link_resp.status_code != 200:
                time_taken_s = f"({time.time() - start_time:.2f} —Å–µ–∫)"
                if self.debug:
                    print(f"  ‚úó –û—à–∏–±–∫–∞ API: {link_resp.status_code} –¥–ª—è [#{chapter_posi}] {time_taken_s}")
                else:
                    print(f"\r  ‚úó –û—à–∏–±–∫–∞ API: {link_resp.status_code} –¥–ª—è [#{chapter_posi}] {time_taken_s}")
                return False

            json_data = link_resp.json()
            raw_url = json_data.get("data")

            if not raw_url:
                time_taken_s = f"({time.time() - start_time:.2f} —Å–µ–∫)"
                if self.debug:
                    print(f"  ‚úó API –Ω–µ –≤–µ—Ä–Ω—É–ª —Å—Å—ã–ª–∫—É –¥–ª—è [#{chapter_posi}] (error: {json_data.get('error')}) {time_taken_s}")
                else:
                    print(f"\r  ‚úó API –Ω–µ –≤–µ—Ä–Ω—É–ª —Å—Å—ã–ª–∫—É –¥–ª—è [#{chapter_posi}] (error: {json_data.get('error')}) {time_taken_s}")
                return False

            download_url = "https:" + raw_url.replace("\\/", "/")

            # if self.debug:
            #     print(f"  [DEBUG] API response: {json_data}")
            #     print(f"  [DEBUG] Download URL: {download_url}")

            parsed_url = urlparse(download_url)
            ext = Path(parsed_url.path).suffix
            if ext not in ['.zip', '.cbr']:
                ext = '.cbr'
            temp_archive_path = chapter_folder / f"__archive__{ext}"

            download_headers = self.headers.copy()
            download_headers['Referer'] = manga_url
            archive_response = self.session.get(download_url, headers=download_headers, stream=True, timeout=60)

            # if self.debug:
            #     print(f"  [DEBUG] Request headers: {dict(archive_response.request.headers)}")
            #     print(f"  [DEBUG] Response status: {archive_response.status_code}")
            #     print(f"  [DEBUG] Response headers: {dict(archive_response.headers)}")
            #     print(f"  [DEBUG] Session cookies: {dict(self.session.cookies)}")

            if archive_response.status_code == 200:
                with open(temp_archive_path, 'wb') as f:
                    for chunk in archive_response.iter_content(chunk_size=8192):
                        f.write(chunk)

                extracted = False
                try:
                    with zipfile.ZipFile(temp_archive_path, 'r') as zf:
                        zf.extractall(chapter_folder)
                    extracted = True
                except (zipfile.BadZipFile, zipfile.LargeZipFile):
                    try:
                        with rarfile.RarFile(temp_archive_path, 'r') as rf:
                            rf.extractall(chapter_folder)
                        extracted = True
                    except Exception:
                        time_taken_s = f"({time.time() - start_time:.2f} —Å–µ–∫)"
                        if self.debug:
                            print(f"  ‚úó –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏: {chapter_title_safe} (–Ω–µ ZIP –∏ –Ω–µ RAR) {time_taken_s}")
                        else:
                            print(f"\r  ‚úó –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏: {chapter_title_safe} (–Ω–µ ZIP –∏ –Ω–µ RAR) {time_taken_s}")
                        return False
                except Exception:
                    time_taken_s = f"({time.time() - start_time:.2f} —Å–µ–∫)"
                    if self.debug:
                        print(f"  ‚úó –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ (ZIP): {chapter_title_safe} {time_taken_s}")
                    else:
                        print(f"\r  ‚úó –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ (ZIP): {chapter_title_safe} {time_taken_s}")
                    return False
                finally:
                    if temp_archive_path.exists():
                        try:
                            temp_archive_path.unlink()
                        except Exception:
                            pass

                time_taken_s = f"({time.time() - start_time:.2f} —Å–µ–∫)"
                # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É "–°–∫–∞—á–∏–≤–∞—é..."
                if self.debug:
                    print(f"  ‚úì {chapter_title_safe} {time_taken_s}")
                else:
                    print(f"\r  ‚úì {chapter_title_safe} {time_taken_s}{' ' * 20}")
                return extracted
            else:
                time_taken_s = f"({time.time() - start_time:.2f} —Å–µ–∫)"
                if self.debug:
                    print(f"  ‚úó –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {archive_response.status_code} {time_taken_s}")
                else:
                    print(f"\r  ‚úó –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {archive_response.status_code} {time_taken_s}")
                return False

        except Exception as e:
            time_taken_s = f"({time.time() - start_time:.2f} —Å–µ–∫)"
            if self.debug:
                print(f"  ‚úó –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {chapter_title_safe} ({e}) {time_taken_s}")
            else:
                print(f"\r  ‚úó –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {chapter_title_safe} ({e}) {time_taken_s}")
            if temp_archive_path and temp_archive_path.exists():
                try:
                    temp_archive_path.unlink()
                except Exception:
                    pass
            return False

    def download_manga(self, manga_url, output_dir="manga", start_chapter=None, end_chapter=None):
        if not self.load_cookies():
            if not self.get_cookies_via_selenium():
                print(f"\n{RED}‚úó –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è{ENDC}")
                return False

        clear_console()
        print_menu()
        news_id = self.get_manga_id_from_url(manga_url)
        if not news_id:
            print(f"\n{RED}‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å ID –º–∞–Ω–≥–∏ –∏–∑ URL{ENDC}")
            return False

        print(f"\nüìñ ID –º–∞–Ω–≥–∏: {news_id}")
        chapters, manga_title = self.get_chapters_list(manga_url)

        if not chapters or not manga_title:
            print(f"\n{RED}‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥–ª–∞–≤ –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–Ω–≥–∏{ENDC}")
            print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
            print("    1. –£–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª comx_cookies.json –∏ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –∑–∞–Ω–æ–≤–æ")
            print("    2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å URL –º–∞–Ω–≥–∏")
            return False

        if start_chapter or end_chapter:
            start = start_chapter or 1
            end = end_chapter or 99999
            chapters = [ch for ch in chapters if start <= ch.get('posi', 0) <= end]
            print(f"üìå –í—ã–±—Ä–∞–Ω –¥–∏–∞–ø–∞–∑–æ–Ω: –≥–ª–∞–≤—ã {start}-{end} ({len(chapters)} —à—Ç.)\n")

        base_manga_folder = Path(output_dir) / manga_title
        base_manga_folder.mkdir(parents=True, exist_ok=True)

        print(SEPARATOR)
        print(f"{CYAN}{BOLD}–°–ö–ê–ß–ò–í–ê–ù–ò–ï –ì–õ–ê–í{ENDC}")
        print(SEPARATOR)

        total_start_time = time.time()
        success_count = 0

        for idx, chapter in enumerate(chapters, 1):
            try:
                if self.download_chapter(chapter, base_manga_folder, news_id, manga_url):
                    success_count += 1
                time.sleep(1)
            except KeyboardInterrupt:
                print(f"\n\n{YELLOW}‚ö† –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º{ENDC}")
                break
            except Exception as e:
                print(f"  {RED}‚úó –û—à–∏–±–∫–∞: {e}{ENDC}")
                continue

        total_time_taken = time.time() - total_start_time

        print(SEPARATOR)
        print(f"{GREEN}{BOLD}–ó–ê–í–ï–†–®–ï–ù–û{ENDC}")
        print(SEPARATOR)
        print(f"‚úì –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ: {success_count}/{len(chapters)} –≥–ª–∞–≤")
        print(f"üïí –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time_taken:.2f} —Å–µ–∫")
        print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {base_manga_folder.absolute()}\n")

        if success_count > 0:
            self.prompt_pdf_creation(base_manga_folder, manga_title)

        return True

    @staticmethod
    def sanitize_filename(filename):
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        filename = re.sub(r'[\s_]+', ' ', filename)
        return filename.strip()

    @staticmethod
    def parse_range(range_str):
        range_str = range_str.strip()
        if not range_str:
            return None, None
        if '-' in range_str:
            parts = range_str.split('-')
            try:
                start = int(parts[0]) if parts[0] else None
            except ValueError:
                start = None
            try:
                end = int(parts[1]) if parts[1] else None
            except ValueError:
                end = None
            return start, end
        else:
            try:
                num = int(range_str)
                return num, num
            except ValueError:
                return None, None

    @staticmethod
    def parse_chapter_sort_key(folder_name):
        """Extract volume/chapter numbers from folder name for sorting."""
        # Pattern: "Vol. X Ch. Y - Title"
        match = re.match(r'Vol\.\s*([\d.]+)\s*Ch\.\s*([\d.]+)', folder_name)
        if match:
            try:
                vol = float(match.group(1))
                ch = float(match.group(2))
                return (vol, ch)
            except ValueError:
                pass

        # Pattern: "Ch. X - Title"
        match = re.match(r'Ch\.\s*([\d.]+)', folder_name)
        if match:
            try:
                ch = float(match.group(1))
                return (0, ch)
            except ValueError:
                pass

        # Fallback: extract any number
        numbers = re.findall(r'[\d.]+', folder_name)
        if numbers:
            try:
                return (0, float(numbers[0]))
            except ValueError:
                pass

        return (0, 0)

    @staticmethod
    def get_sorted_chapter_folders(manga_folder):
        """Return chapter folders sorted by volume/chapter number."""
        folders = [f for f in manga_folder.iterdir() if f.is_dir()]
        folders.sort(key=lambda f: ComXLifeDownloader.parse_chapter_sort_key(f.name))
        return folders

    @staticmethod
    def get_sorted_images(chapter_folder):
        """Return image files sorted naturally (2.jpg before 10.jpg)."""
        image_extensions = {'.jpg', '.jpeg', '.png', '.webp'}
        images = [f for f in chapter_folder.iterdir()
                  if f.is_file() and f.suffix.lower() in image_extensions]

        def natural_sort_key(path):
            # Extract numbers for natural sorting
            parts = re.split(r'(\d+)', path.stem)
            return [int(p) if p.isdigit() else p.lower() for p in parts]

        images.sort(key=natural_sort_key)
        return images

    @staticmethod
    def convert_webp_to_jpeg(webp_path, temp_dir):
        """Convert WebP image to JPEG for img2pdf compatibility."""
        try:
            img = Image.open(webp_path)
            # Handle RGBA/alpha channel
            if img.mode in ('RGBA', 'LA', 'P'):
                # Create white background
                background = Image.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')

            jpeg_path = Path(temp_dir) / f"{webp_path.stem}.jpg"
            img.save(jpeg_path, 'JPEG', quality=95)
            return jpeg_path
        except Exception as e:
            print(f"    {YELLOW}‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {webp_path.name}: {e}{ENDC}")
            return None

    def create_pdf(self, manga_folder, output_pdf_path):
        """Create PDF from all chapter images."""
        print(f"\n{CYAN}üìÑ –°–æ–∑–¥–∞–Ω–∏–µ PDF...{ENDC}")

        chapter_folders = self.get_sorted_chapter_folders(manga_folder)
        if not chapter_folders:
            print(f"{RED}‚úó –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫ —Å –≥–ª–∞–≤–∞–º–∏{ENDC}")
            return False

        all_images = []
        temp_dir = None

        try:
            # Collect all images
            for folder in chapter_folders:
                images = self.get_sorted_images(folder)
                if not images:
                    print(f"  {YELLOW}‚ö† –ü—É—Å—Ç–∞—è –ø–∞–ø–∫–∞: {folder.name}{ENDC}")
                    continue
                all_images.extend(images)

            if not all_images:
                print(f"{RED}‚úó –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è PDF{ENDC}")
                return False

            print(f"  –ù–∞–π–¥–µ–Ω–æ {len(all_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {len(chapter_folders)} –≥–ª–∞–≤–∞—Ö")

            # Process images (convert WebP if needed)
            temp_dir = tempfile.mkdtemp()
            image_paths = []

            for idx, img_path in enumerate(all_images):
                # Show progress
                progress = (idx + 1) / len(all_images) * 100
                print(f"\r  –û–±—Ä–∞–±–æ—Ç–∫–∞: {progress:.0f}%", end="", flush=True)

                if img_path.suffix.lower() == '.webp':
                    converted = self.convert_webp_to_jpeg(img_path, temp_dir)
                    if converted:
                        image_paths.append(str(converted))
                else:
                    image_paths.append(str(img_path))

            print("\r  –û–±—Ä–∞–±–æ—Ç–∫–∞: 100%   ")

            if not image_paths:
                print(f"{RED}‚úó –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ PDF{ENDC}")
                return False

            # Create PDF
            print("  –ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF...")
            with open(output_pdf_path, 'wb') as f:
                f.write(img2pdf.convert(image_paths))

            # Report file size
            file_size = output_pdf_path.stat().st_size
            if file_size >= 1024 * 1024 * 1024:
                size_str = f"{file_size / (1024 * 1024 * 1024):.2f} –ì–ë"
            elif file_size >= 1024 * 1024:
                size_str = f"{file_size / (1024 * 1024):.2f} –ú–ë"
            else:
                size_str = f"{file_size / 1024:.2f} –ö–ë"

            print(f"{GREEN}‚úì PDF —Å–æ–∑–¥–∞–Ω: {output_pdf_path} ({size_str}){ENDC}")
            return True

        except KeyboardInterrupt:
            print(f"\n{YELLOW}‚ö† –°–æ–∑–¥–∞–Ω–∏–µ PDF –ø—Ä–µ—Ä–≤–∞–Ω–æ{ENDC}")
            if output_pdf_path.exists():
                output_pdf_path.unlink()
            return False
        except Exception as e:
            print(f"{RED}‚úó –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PDF: {e}{ENDC}")
            return False
        finally:
            # Clean up temp directory
            if temp_dir and os.path.exists(temp_dir):
                shutil.rmtree(temp_dir, ignore_errors=True)

    def delete_manga_folder(self, manga_folder):
        """Delete the entire manga folder with all images."""
        try:
            shutil.rmtree(manga_folder)
            print(f"‚úì –£–¥–∞–ª–µ–Ω–∞ –ø–∞–ø–∫–∞: {manga_folder.name}")
        except Exception as e:
            print(f"  {YELLOW}‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {manga_folder.name}: {e}{ENDC}")

    def prompt_pdf_creation(self, manga_folder, manga_title):
        """Ask user if they want to create PDF and optionally delete originals."""
        try:
            questions = [
                inquirer.Confirm('create_pdf',
                                 message="üìÑ –°–æ–∑–¥–∞—Ç—å PDF –∏–∑ –≤—Å–µ—Ö –≥–ª–∞–≤?",
                                 default=True),
            ]
            answers = inquirer.prompt(questions)

            if not answers or not answers['create_pdf']:
                return

            # Create PDF in parent directory (e.g., Manga/Title.pdf instead of Manga/Title/Title.pdf)
            pdf_filename = f"{manga_title}.pdf"
            output_pdf_path = manga_folder.parent / pdf_filename

            if not self.create_pdf(manga_folder, output_pdf_path):
                return

            # Ask about deleting originals
            questions = [
                inquirer.Confirm('delete_originals',
                                 message="üóë  –£–¥–∞–ª–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è?",
                                 default=False),
            ]
            answers = inquirer.prompt(questions)

            if answers and answers['delete_originals']:
                self.delete_manga_folder(manga_folder)

        except KeyboardInterrupt:
            print(f"\n{YELLOW}‚ö† –û—Ç–º–µ–Ω–µ–Ω–æ{ENDC}")

def main():
    if sys.version_info < (3, 7):
        print(f"{RED}‚úó –û—à–∏–±–∫–∞: –≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —Ç—Ä–µ–±—É–µ—Ç Python 3.7+.{ENDC}")
        sys.exit(1)

    clear_console()
    print_menu()

    try:
        questions = [
            inquirer.List('browser',
                          message="üîß –í—ã–±–µ—Ä–∏—Ç–µ –±—Ä–∞—É–∑–µ—Ä –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏",
                          choices=['Chrome', 'Firefox'],
                          carousel=True),
        ]
        answers = inquirer.prompt(questions)
        if not answers:
            raise KeyboardInterrupt

        browser_name = answers['browser'].lower()
        downloader = ComXLifeDownloader(browser_choice=browser_name, debug=True)

        while True:
            clear_console()
            print_menu()

            questions = [
                inquirer.Text('query',
                              message="üìñ –í–≤–µ–¥–∏—Ç–µ URL –∏–ª–∏ –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–Ω–≥–∏ (Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞)"),
            ]
            answers = inquirer.prompt(questions)

            if not answers or not answers['query']:
                raise KeyboardInterrupt

            input_str = answers['query'].strip()
            manga_url = None

            if 'com-x.life' in input_str and 'http' in input_str:
                manga_url = input_str
            else:
                clear_console()
                print_menu()
                print(f"\n{YELLOW}üîç –ò—â—É '{input_str}'...{ENDC}")
                results = downloader.fetch_search_results_sync(input_str)

                clear_console()
                print_menu()

                if not results:
                    print(f"{RED}‚úó –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{input_str}'.{ENDC}")
                    time.sleep(2)
                    continue

                if len(results) == 1:
                    manga_url = results[0]['url']
                    print(f"‚úì –ù–∞–π–¥–µ–Ω–∞ 1 –º–∞–Ω–≥–∞: {results[0]['title']}")
                else:
                    print(f"\n{YELLOW}üìö –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –í—ã–±–µ—Ä–∏—Ç–µ:{ENDC}")
                    for i, res in enumerate(results, 1):
                        print(f"  {i:02d}: {res['title']}")

                    print(f"\n{GREY}(–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞){ENDC}")
                    choice_str = input(f"{CYAN}–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä: {ENDC}").strip()

                    if not choice_str:
                        continue

                    try:
                        choice_idx = int(choice_str) - 1
                        if 0 <= choice_idx < len(results):
                            manga_url = results[choice_idx]['url']
                            print(f"‚úì –í—ã–±—Ä–∞–Ω–æ: {results[choice_idx]['title']}")
                        else:
                            print(f"{RED}‚úó –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä.{ENDC}")
                            time.sleep(2)
                            continue
                    except ValueError:
                        print(f"{RED}‚úó –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥.{ENDC}")
                        time.sleep(2)
                        continue

            if not manga_url:
                 continue

            questions = [
                inquirer.Text('output',
                              message="üìÅ –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
                              default='Manga'),
                inquirer.Text('range',
                              message="üí° –£–∫–∞–∂–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω (Enter = –≤—Å–µ)",
                              default=''),
            ]
            answers = inquirer.prompt(questions)

            if not answers:
                continue

            output_dir = answers['output'].strip() or 'manga'
            start_chapter, end_chapter = ComXLifeDownloader.parse_range(answers['range'])

            downloader.download_manga(manga_url, output_dir, start_chapter, end_chapter)

            print(f"\n{CYAN}–ù–∞–∂–º–∏—Ç–µ Enter, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫...{ENDC}")
            input()

    except KeyboardInterrupt:
        print()
        sys.exit(0)
    except Exception as e:
        print(f"\n{RED}‚úó –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}{ENDC}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
